{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pid 1780695's current affinity list: 0-63\n",
      "pid 1780695's new affinity list: 0-47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeremyl/.pyenv/versions/3.9.6/envs/venv_SARRA/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import rioxarray as rio\n",
    "from rosetta import rosetta, SoilData\n",
    "import numpy as np\n",
    "import os\n",
    "from p_tqdm import p_map\n",
    "from tqdm import tqdm\n",
    "from scipy.interpolate import interp2d\n",
    "\n",
    "\n",
    "# Set the number of CPUs to use\n",
    "num_cpus = 48\n",
    "# Use the taskset command to set the CPU affinity for the current process\n",
    "os.system('taskset -p -c 0-{} {}'.format(num_cpus-1, os.getpid()))\n",
    "\n",
    "\n",
    "# turn off deprecation warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading iSDA datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘../data/iSDA_data/sol_silt_tot_psa_m_30m_0..20cm_2001..2017_v0.13_wgs84.tif’ already there; not retrieving.\n",
      "\n",
      "File ‘../data/iSDA_data/sol_clay_tot_psa_m_30m_0..20cm_2001..2017_v0.13_wgs84.tif’ already there; not retrieving.\n",
      "\n",
      "File ‘../data/iSDA_data/sol_sand_tot_psa_m_30m_0..20cm_2001..2017_v0.13_wgs84.tif’ already there; not retrieving.\n",
      "\n",
      "File ‘../data/iSDA_data/sol_db_od_m_30m_0..20cm_2001..2017_v0.13_wgs84.tif’ already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# - silt https://zenodo.org/record/4094610\n",
    "!wget -nc -P ../data/iSDA_data/ https://zenodo.org/record/4094610/files/sol_silt_tot_psa_m_30m_0..20cm_2001..2017_v0.13_wgs84.tif\n",
    "\n",
    "# - clay https://zenodo.org/record/4085160\n",
    "!wget -nc -P ../data/iSDA_data/ https://zenodo.org/record/4085160/files/sol_clay_tot_psa_m_30m_0..20cm_2001..2017_v0.13_wgs84.tif\n",
    "\n",
    "# - sand https://zenodo.org/record/4094607\n",
    "!wget -nc -P ../data/iSDA_data/ https://zenodo.org/record/4094607/files/sol_sand_tot_psa_m_30m_0..20cm_2001..2017_v0.13_wgs84.tif\n",
    "\n",
    "# - bulk density https://zenodo.org/record/4087905\n",
    "!wget -nc -P ../data/iSDA_data/ https://zenodo.org/record/4087905/files/sol_db_od_m_30m_0..20cm_2001..2017_v0.13_wgs84.tif"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining available water content computation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_theta_a(args):\n",
    "\n",
    "    from scipy.interpolate import griddata\n",
    "\n",
    "    def interpolate_xarray(arr):\n",
    "        y, x = np.indices(arr.shape)\n",
    "        points = np.column_stack((y.ravel(), x.ravel()))\n",
    "\n",
    "        values = arr.values.ravel()\n",
    "        nan_mask = np.isnan(values)\n",
    "        missing_points = points[nan_mask]\n",
    "\n",
    "        if not missing_points.size:\n",
    "            return arr\n",
    "\n",
    "        valid_points = points[~nan_mask]\n",
    "        valid_values = values[~nan_mask]\n",
    "\n",
    "        interpolated_values = griddata(valid_points, valid_values, missing_points, method='nearest')\n",
    "\n",
    "        # Reshape the nan_mask to match the shape of the input DataArray\n",
    "        nan_mask_2d = nan_mask.reshape(arr.shape)\n",
    "\n",
    "        arr.values[nan_mask_2d] = interpolated_values\n",
    "\n",
    "        return arr  \n",
    "\n",
    "    left, bottom, right, top = [args[0], args[1], args[2], args[3]]\n",
    "\n",
    "    filename = f'theta_a_mm_per_cm_{left}_{bottom}_{right}_{top}.tif'\n",
    "    filepath = os.path.join('../data/output/', filename)\n",
    "\n",
    "    if filename in os.listdir('../data/output/'):\n",
    "        pass\n",
    "    else:\n",
    "\n",
    "        data_path = \"../data/iSDA_data/\"\n",
    "\n",
    "        path = {\n",
    "            \"sand\": os.path.join(data_path, \"sol_sand_tot_psa_m_30m_0..20cm_2001..2017_v0.13_wgs84.tif\"),\n",
    "            \"silt\": os.path.join(data_path, \"sol_silt_tot_psa_m_30m_0..20cm_2001..2017_v0.13_wgs84.tif\"),\n",
    "            \"clay\": os.path.join(data_path, \"sol_clay_tot_psa_m_30m_0..20cm_2001..2017_v0.13_wgs84.tif\"),\n",
    "            \"bulk_density\": os.path.join(data_path, \"sol_db_od_m_30m_0..20cm_2001..2017_v0.13_wgs84.tif\"),\n",
    "        }\n",
    "\n",
    "        # create an empty xarray dataset\n",
    "        ds = xr.Dataset()\n",
    "\n",
    "        for layer in path :\n",
    "            # Open file using xarray\n",
    "            # da = xr.open_rasterio(path[layer]).squeeze(\"band\", drop=True)\n",
    "            # open using rioxarray \n",
    "            da = rio.open_rasterio(path[layer], masked=True).squeeze(\"band\", drop=True)\n",
    "\n",
    "            # Subset the DataArray based on the bounding box\n",
    "            da = da.sel(x=slice(left, right), y=slice(top, bottom))\n",
    "\n",
    "            # Add the DataArray to the Dataset\n",
    "            ds[layer] = da\n",
    "\n",
    "        # prepare rosetta dataframe\n",
    "        df_rosetta = pd.DataFrame({\"sand\": ds[\"sand\"].to_numpy().flatten(),\n",
    "                                \"silt\": ds[\"silt\"].to_numpy().flatten(),\n",
    "                                \"clay\": ds[\"clay\"].to_numpy().flatten(),\n",
    "                                    \"bulk_density\": ds[\"bulk_density\"].to_numpy().flatten(),\n",
    "                                })\n",
    "\n",
    "        # normalize values\n",
    "        # df_rosetta[\"sand_norm\"] = df_rosetta[\"sand\"] / df_rosetta[[\"sand\",\"clay\",\"silt\"]].sum(axis=1) * 100.0\n",
    "        # df_rosetta[\"silt_norm\"] = df_rosetta[\"silt\"] / df_rosetta[[\"sand\",\"clay\",\"silt\"]].sum(axis=1) * 100.0\n",
    "        # df_rosetta[\"clay_norm\"] = df_rosetta[\"clay\"] / df_rosetta[[\"sand\",\"clay\",\"silt\"]].sum(axis=1) * 100.0\n",
    "        df_rosetta[\"bulk_density\"] = df_rosetta[\"bulk_density\"] * 10.0 # conversion from raw values to kg/m3\n",
    "        df_rosetta[\"bulk_density\"] = df_rosetta[\"bulk_density\"] / 1000.0 # conversion from kg/m3 to g/cm3\n",
    "\n",
    "        \n",
    "        # compute Rosetta\n",
    "        # mean, stdev, codes = rosetta(rosetta_version = 3, soildata = SoilData.from_array(df_rosetta[[\"sand_norm\",\"silt_norm\",\"clay_norm\", \"bulk_density\"]].to_numpy()))\n",
    "        mean, stdev, codes = rosetta(rosetta_version = 3, soildata = SoilData.from_array(df_rosetta[[\"sand\",\"silt\",\"clay\", \"bulk_density\"]].to_numpy()))\n",
    "\n",
    "        \n",
    "        # reverse flatteing\n",
    "        ds[\"theta_r_mean\"] = (ds[\"sand\"].dims, mean[:,0].reshape(ds[\"sand\"].shape))\n",
    "        ds[\"theta_r_std\"] = (ds[\"sand\"].dims, stdev[:,0].reshape(ds[\"sand\"].shape))\n",
    "        ds[\"theta_s_mean\"] = (ds[\"sand\"].dims, mean[:,1].reshape(ds[\"sand\"].shape))\n",
    "        ds[\"theta_s_std\"] = (ds[\"sand\"].dims, stdev[:,1].reshape(ds[\"sand\"].shape))\n",
    "        ds[\"log10(alpha)\"] = (ds[\"sand\"].dims, mean[:,2].reshape(ds[\"sand\"].shape))\n",
    "        ds[\"log10(n)\"] = (ds[\"sand\"].dims, mean[:,3].reshape(ds[\"sand\"].shape))\n",
    "        ds[\"codes\"] = (ds[\"sand\"].dims, codes.reshape(ds[\"sand\"].shape))\n",
    "        # ds[\"log10(ksat)\"] = (ds[\"sand\"].dims, mean[:,4].reshape(ds[\"sand\"].shape))\n",
    "\n",
    "        # from usda documentation :\n",
    "        # Column \tParameter\n",
    "        # 0 \ttheta_r, residual water content\n",
    "        # 1 \ttheta_s, saturated water content\n",
    "        # 2 \tlog10(alpha), 'alpha' shape parameter, log10(1/cm)\n",
    "        # 3 \tlog10(npar), 'n' shape parameter\n",
    "        # 4 \tlog10(Ksat), saturated hydraulic conductivity, log10(cm/day)\n",
    "\n",
    "        # formula to compute the volumic water content for a given suction pressure ?\n",
    "        # the van Genuchten-Mualem model provides a functional relationship between\n",
    "        # volumetric water content (θ) and soil suction pressure (h). The formula is as\n",
    "        # follows: θ(h) = θr + [θs - θr] / {1 + (αh)^npar}^(1-1/npar)\n",
    "\n",
    "        # where:\n",
    "        #     θr is the residual water content; θs is the saturated water content; α is\n",
    "        #     the inverse of the characteristic pore size; n is the shape parameter that\n",
    "        #     governs the degree of curvature of the θ(h) curve; Ksat is the saturated\n",
    "        #     hydraulic conductivity; h is the soil suction pressure (positive when the\n",
    "        #     soil is dry and negative when the soil is wet).\n",
    "\n",
    "        ds[\"alpha\"] = 10.0**ds[\"log10(alpha)\"]\n",
    "        ds[\"npar\"] = 10.0**ds[\"log10(n)\"]\n",
    "        # h_fc = 33.0 # kPa\n",
    "        # h_pwp = 1500.0 # kPa\n",
    "        h_fc = 33.0 * 10.1972  # kPa to cm H2O\n",
    "        h_pwp = 1500.0 * 10.1972  # kPa to cm H2O\n",
    "\n",
    "        # computing the volumetric water content at field capacity and wilting point according to the van Genuchten model\n",
    "        ds[\"theta_fc\"] = ds[\"theta_r_mean\"] + (ds[\"theta_s_mean\"] - ds[\"theta_r_mean\"]) / (1 + (ds[\"alpha\"] * h_fc) ** ds[\"npar\"])**(1-1/ds[\"npar\"])\n",
    "        ds[\"theta_wp\"] = ds[\"theta_r_mean\"] + (ds[\"theta_s_mean\"] - ds[\"theta_r_mean\"]) / (1 + (ds[\"alpha\"] * h_pwp) ** ds[\"npar\"])**(1-1/ds[\"npar\"])\n",
    "\n",
    "        # converting from %vol to mm\n",
    "        ds[\"theta_fc_mm\"] = ds[\"theta_fc\"] * 10.0 # converting bulk density from raw values to g/cm3, then managing cm/mm conversion\n",
    "        ds[\"theta_wp_mm\"] = ds[\"theta_wp\"] * 10.0 # converting bulk density from raw values to g/cm3, then managing cm/mm conversion\n",
    "\n",
    "        # computing the available water content theta_a \n",
    "        ds[\"theta_a\"] = ds[\"theta_fc\"] - ds[\"theta_wp\"]\n",
    "        ds[\"theta_a_mm\"] = ds[\"theta_fc_mm\"] - ds[\"theta_wp_mm\"]  # value in mm of water per vertical cm of soil\n",
    "\n",
    "\n",
    "        ds[\"theta_a_mm_interp\"] = interpolate_xarray(ds[\"theta_a_mm\"])\n",
    "\n",
    "\n",
    "\n",
    "        export_list = [\n",
    "            \"theta_r_mean\",\n",
    "            \"theta_r_std\",\n",
    "            \"theta_s_mean\",\n",
    "            \"theta_s_std\",\n",
    "            \"alpha\",\n",
    "            \"npar\",\n",
    "            \"theta_fc\",\n",
    "            \"theta_wp\",\n",
    "            \"theta_a\",\n",
    "            \"theta_a_mm\",\n",
    "            \"theta_a_mm_interp\",\n",
    "            \"codes\",\n",
    "        ]\n",
    "\n",
    "\n",
    "        # exporting theta_a_mm as geotiff\n",
    "        for export_name in export_list:\n",
    "            \n",
    "            if not os.path.exists(os.path.join('../data/output/',export_name)):\n",
    "                os.makedirs(os.path.join('../data/output/',export_name))\n",
    "\n",
    "            filepath = os.path.join('../data/output/',export_name, f'{export_name}_{left}_{bottom}_{right}_{top}.tif')\n",
    "            ds[export_name].rio.to_raster(filepath)\n",
    "\n",
    "        return filename\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define ROI and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining dictionary of coordinates for areas of interest\n",
    "# bounding box coordinates format : [lat NW/top, lon NW/left, lat SE/bottom, lon SE/right]\n",
    "area = {\n",
    "    'burkina': [16, -6, 9, 3],\n",
    "    'burkina_close': [15.1, -5.6, 9.4, 2.4],\n",
    "    'niger':[23.8, -0.5, 11.3, 15.9],\n",
    "    'west_africa':[29, -20, 3.5, 26],\n",
    "    'burkina_bobo_dioulasso': [11.20, -4.3, 11.15, -4.25],\n",
    "    'burkina_bobo_dioulasso_large': [11.25, -4.3, 11.15, -4.20], # corresponding to [-4.3000, 11.1500, -4.2500, 11.2000] in left, bottom, right, top\n",
    "    'burkina_bobo_dioulasso_xlarge': [11.4, -4.4, 11.1, -4.10], # corresponding to [-4.3000, 11.1500, -4.2500, 11.2000] in left, bottom, right, top\n",
    "    'burkina_bobo_dioulasso_xxlarge': [11.6, -4.6, 10.8, -3.90], # corresponding to [-4.3000, 11.1500, -4.2500, 11.2000] in left, bottom, right, top\n",
    "    }\n",
    "\n",
    "# selecting area of interest\n",
    "selected_area = \"burkina_close\"\n",
    "resolution = 0.1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing theta_a_mm_0-20cm: 100%|██████████| 16/16 [02:27<00:00,  9.21s/it]\n"
     ]
    }
   ],
   "source": [
    "# loading roi coordinates\n",
    "top, left, bottom, right = [value for value in area[selected_area]]\n",
    "\n",
    "# Create a list of sub-windows\n",
    "sub_windows = []\n",
    "for x in np.arange(left, right, resolution):\n",
    "    for y in np.arange(bottom, top, resolution):\n",
    "        sub_windows.append((np.round(x,3), np.round(y,3), np.round(x+resolution,3), np.round(y+resolution,3)))\n",
    "\n",
    "# parallelizing the computation of calc_theta_a across sub_windows\n",
    "r = p_map(calc_theta_a, sub_windows, num_cpus=num_cpus, desc=\"Computing theta_a_mm_0-20cm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading roi coordinates\n",
    "top, left, bottom, right = [value for value in area[selected_area]]\n",
    "\n",
    "# Create a list of sub-windows\n",
    "sub_windows = []\n",
    "for x in np.arange(left, right, resolution):\n",
    "    for y in np.arange(bottom, top, resolution):\n",
    "        sub_windows.append((np.round(x,3), np.round(y,3), np.round(x+resolution,3), np.round(y+resolution,3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_SARRA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da0d53dc61c42ab8f73b378d4b74c8bb6ff71cd05cac6de5d0d52f0bac420084"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
